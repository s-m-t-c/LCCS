{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import datacube\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "from matplotlib import pyplot as plt\n",
    "import geopandas as gp\n",
    "import fiona\n",
    "import glob\n",
    "from datacube import helpers\n",
    "import rasterio\n",
    "import sklearn\n",
    "import graphviz \n",
    "import pdb\n",
    "import sklearn\n",
    "# Import external functions from dea-notebooks using relative link to 10_Scripts\n",
    "sys.path.append('/g/data/u46/users/sc0554/dea-notebooks/Scripts')\n",
    "from dea_classificationtools import get_training_data_for_shp\n",
    "from dea_plotting import display_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_list = glob.glob('/g/data1a/r78/LCCS_Aberystwyth/training_data/2015/*.shp')\n",
    "out_train = []\n",
    "for shp_num, path in enumerate(shp_list):\n",
    "    print(\"[{:02}/{:02}]: {}\".format(shp_num+1, len(shp_list), path))\n",
    "    try:\n",
    "        column_names = dea_classificationtools.get_training_data_for_shp(path, out_train, product = 'ls8_nbart_tmad_annual', \n",
    "                                                                     time = ('2015-01-01', '2015-12-31'), \n",
    "                                                                     crs = 'EPSG:3577', field='classnum')\n",
    "    except Exception as e:\n",
    "        print(\"Failed to extract data: {}\".format(e))\n",
    "    print(\"\\n extracted pixels\")\n",
    "    \n",
    "model_input = np.vstack(out_train)\n",
    "print(model_input.shape)\n",
    "# np.savetxt(\"train_input_tmad.txt\", model_input, header = ' '.join(column_names), fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = np.loadtxt('train_input.txt', delimiter = \" \", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialise classifier\n",
    "model = RandomForestClassifier(n_estimators=100, verbose=2, n_jobs=-1)\n",
    "# Fit classifier add \"==215\" to make a single class prediction.\n",
    "model = model.fit(model_input[:,1:], model_input[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision tree\n",
    "from sklearn import tree\n",
    "# Initialise classifier\n",
    "model = tree.DecisionTreeClassifier(random_state=0, max_depth=5)\n",
    "# Fit classifier add \"==215\" to make a single class prediction.\n",
    "model = model.fit(model_input[:,1:], model_input[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(model_input[:,1:], model_input[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(data.data_vars)\n",
    "print(feature_names)\n",
    "target_names = np.array(('Natural Terrestrial Vegetated', 'Artificial Surface', 'Natural Surface', 'Artificail Water', 'Natural Water'))\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the structure of the tree\n",
    "plt.figure(figsize=(25,8))\n",
    "sklearn.tree.plot_tree(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_out = model.predict(model_input[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the area you want to predict land cover here\n",
    "\n",
    "# Lake Eyre\n",
    "# x = (550000, 600000)\n",
    "# y = (-3000000, -2950000)\n",
    "# x = (-1000000, -950000)\n",
    "# y = (-3400000, -3350000)\n",
    "# x = (-1200000, -1299850)\n",
    "# y = (-3600000, -3500125)\n",
    "\n",
    "# # Coorong\n",
    "# x = (600000, 700000)\n",
    "# y = (-3950000, -3850000)\n",
    "\n",
    "# Kakadu\n",
    "x = (0,100000)\n",
    "y = (-1350000,-1250000)\n",
    "\n",
    "query = {'time': ('2015-01-01', '2015-02-01')}\n",
    "query['x'] = (x[0], x[1])\n",
    "query['y'] = (y[0], y[1])\n",
    "query['crs'] = 'EPSG:3577'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(x, y, crs=\"EPSG:3577\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = dc.load(product=product, group_by='solar_day', **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.blue.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = calculate_indices(new_data, 'BUI', collection='ga_ls_2')\n",
    "new_data = calculate_indices(new_data, 'BSI', collection='ga_ls_2')\n",
    "new_data = calculate_indices(new_data, 'BSI', collection='ga_ls_2')\n",
    "new_data = calculate_indices(new_data, 'NBI', collection='ga_ls_2')\n",
    "new_data = calculate_indices(new_data, 'EVI', collection='ga_ls_2')\n",
    "new_data = calculate_indices(new_data, 'NDWI', collection='ga_ls_2')\n",
    "new_data = calculate_indices(new_data, 'MSAVI', collection='ga_ls_2')\n",
    "# new_data = new_data.drop(bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = dea_classificationtools.predict_xr(model, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = predicted.isel(time=0).transpose()\n",
    "out = out.to_dataset(name=\"LCCS_L3\")\n",
    "out.attrs['crs']=geometry.CRS(data.crs)\n",
    "# out = out.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.write_geotiff('dtreekak.tif', out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
