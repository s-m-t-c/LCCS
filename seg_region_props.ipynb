{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from skimage.morphology import binary_erosion, binary_dilation, disk, square\n",
    "import pandas as pd\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from datacube import helpers\n",
    "from datacube.utils import geometry\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# PCA\n",
    "\n",
    "# import sklearn\n",
    "sys.path.append('/g/data/u46/users/sc0554/cult_area/LCCS/')\n",
    "\n",
    "# Image Seg\n",
    "\n",
    "from skimage import io\n",
    "from skimage.segmentation import quickshift, felzenszwalb\n",
    "import sklearn.feature_extraction.image\n",
    "import sklearn.cluster\n",
    "from skimage.segmentation import mark_boundaries, slic, watershed\n",
    "from skimage.util import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.impute import SimpleImputer\n",
    "from skimage.filters import sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "dc=datacube.Datacube(config='/home/547/sc0554/datacube.conf', env='lccs_dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product = 'ls8_nbart_tmad_annual'\n",
    "\n",
    "\n",
    "# # Ayr\n",
    "# x = (1500000, 1600000)\n",
    "# y = (-2200000, -2100000)\n",
    "\n",
    "# # Diamentina\n",
    "# x = (800000, 900000)\n",
    "# y = (-2800000, -2700000)\n",
    "\n",
    "# # Gwydir\n",
    "# x = (1600000, 1700000)\n",
    "# y = (-3400000, -3300000)\n",
    "\n",
    "# # Leichhardt\n",
    "# x = (800000, 900000)\n",
    "# y = (-2000000, -1900000)\n",
    "\n",
    "# # Kakadu\n",
    "# x = (0, 100000)\n",
    "# y = (-1350000, -1250000)\n",
    "\n",
    "# # Hobart\n",
    "# x = (1200000, 1300000)\n",
    "# y = (-4800000, -4700000)\n",
    "\n",
    "# # Perth\n",
    "x = (-1550000, -1450000)\n",
    "y = (-3650000, -3550000)\n",
    "\n",
    "# # Murray Valley\n",
    "# x = (1100000, 1200000)\n",
    "# y = (-4000000, -3900000)\n",
    "\n",
    "# Adelaide\n",
    "# x = (550000, 650000)\n",
    "# y = (-3850000, -3750000)\n",
    "\n",
    "# Canberra\n",
    "# x = (1500000, 1600000)\n",
    "# y = (-4000000, -3900000)\n",
    "# min_x = 1500000\n",
    "# max_x = 1600000\n",
    "# min_y = -4000000\n",
    "# max_y = -3900000\n",
    "# res_x = 25\n",
    "# res_y = -25\n",
    "\n",
    "\n",
    "# # Lake Eyre\n",
    "# x = (500000, 600000)\n",
    "# y = (-3000000, -2900000)\n",
    "\n",
    "# # Blue mountains\n",
    "# x = (1600000, 1700000)\n",
    "# y = (-3900000, -3800000)\n",
    "\n",
    "# # Australian Alps\n",
    "# x = (1400000, 1500000)\n",
    "# y = (-4100000, -4000000)\n",
    "\n",
    "# # Collier Range\n",
    "# x = (-1300000, -1200000)\n",
    "# y = (-2700000, -2600000)\n",
    "\n",
    "# # Coorong\n",
    "# x = (600000, 700000)\n",
    "# y = (-3950000, -3850000)\n",
    "\n",
    "# # Brisbane\n",
    "# x = (2000000, 2100000)\n",
    "# y = (-3200000, -3100000)\n",
    "\n",
    "# # Dundas\n",
    "# x = (-1000000, -900000)\n",
    "# y = (-3650000, -3550000)\n",
    "\n",
    "query = {'time': ('2015-01-01', '2015-12-31')}\n",
    "query['x'] = (x[0], x[1])\n",
    "query['y'] = (y[0], y[1])\n",
    "query['crs'] = 'EPSG:3577'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Absolute Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tmad = dc.load(product='ls8_nbart_tmad_annual', **query)\n",
    "tmad = tmad.isel(time=0)\n",
    "tmad = tmad.drop('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(15,5))\n",
    "ax.hist(tmad['edev'].data.ravel(), bins=256, label='edev', alpha=0.65)\n",
    "ax.hist(tmad['sdev'].data.ravel(), bins=256, label='sdev', alpha=0.65)\n",
    "ax.hist(tmad['bcdev'].data.ravel(), bins=256, label='bcdev', alpha=0.65)\n",
    "\n",
    "ax.legend(prop={'size': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of edev NaNs', np.isnan(tmad.edev.data).sum())\n",
    "print('# of edev 0s', (tmad.edev == 0).sum().data)\n",
    "print('# of sdev NaNs', np.isnan(tmad.sdev.data).sum())\n",
    "print('# of sdev 0s', (tmad.sdev == 0).sum().data)\n",
    "print('# of bcdev NaNs', np.isnan(tmad.bcdev.data).sum())\n",
    "print('# of bcdev 0s', (tmad.bcdev == 0).sum().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from xarray, impute NaNs and apply log transform\n",
    "\n",
    "imp_0 = SimpleImputer(missing_values=0, strategy='mean')\n",
    "\n",
    "container = {}\n",
    "for key in tmad.data_vars:\n",
    "    d = tmad[key].data.squeeze()\n",
    "    d = np.nan_to_num(d)\n",
    "    d = np.where(d < 0, 0, d)\n",
    "    d = np.where(d == 1, 0, d)\n",
    "    imp_0.fit(d)\n",
    "    d = imp_0.transform(d)\n",
    "    d = -np.log(d)\n",
    "    container.update({key:d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmad['edev'].data = container['edev']\n",
    "tmad['sdev'].data = container['sdev']\n",
    "tmad['bcdev'].data = container['bcdev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmad_mean = np.float64(np.mean(np.stack([tmad.edev.data, tmad.sdev.data, tmad.bcdev.data], axis=-1), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.percentile(tmad_mean.ravel(), 10)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions of of the data and threshold\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(15,5))\n",
    "ax.hist(tmad['edev'].data.ravel(), bins=256, label='edev', alpha=0.65)\n",
    "ax.hist(tmad['sdev'].data.ravel(), bins=256, label='sdev', alpha=0.65)\n",
    "ax.hist(tmad['bcdev'].data.ravel(), bins=256, label='bcdev', alpha=0.65)\n",
    "ax.hist(tmad_mean.ravel(), bins=256, label='tmad mean', alpha=0.65)\n",
    "ax.axvline(thresh, color='r')\n",
    "\n",
    "ax.legend(prop={'size': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmad_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment input array\n",
    "\n",
    "# %%time\n",
    "# Note: convert2lab=False allows the use of multiband images\n",
    "tmad_seg = quickshift(tmad_mean, kernel_size=7, convert2lab=False, max_dist=500, ratio=0.5)\n",
    "print(\"Quickshift number of segments: %d\" % len(np.unique(tmad_seg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median for each segment\n",
    "\n",
    "tmad_median_seg = scipy.ndimage.median(input=tmad_mean, labels=tmad_seg, index=tmad_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the median - segments output\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(tmad_median_seg)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# Give segments unique labels\n",
    "# labeled = label(cult_area, connectivity = 1)\n",
    "\n",
    "# Create list of labels that do not meet the desired shape requirements\n",
    "frac_dict = {}\n",
    "rect_dict = {}\n",
    "solidity_dict = {}\n",
    "form_dict = {}\n",
    "\n",
    "labels = []\n",
    "for region in regionprops(tmad_seg):\n",
    "    if region.area > 1:\n",
    "        fractal_dimension = 2*np.log(region.perimeter/4)/np.log(region.area)\n",
    "        rectangularity = region.area/(region.major_axis_length*region.minor_axis_length)\n",
    "        solidity = region.convex_area / region.area\n",
    "        form = (4*np.pi*region.area)/np.square(region.perimeter)\n",
    "        # Create dictionary of each property\n",
    "        frac_dict[region.label] = fractal_dimension\n",
    "        rect_dict[region.label] = rectangularity\n",
    "        solidity_dict[region.label] = solidity\n",
    "        form_dict[region.label] = form\n",
    "        \n",
    "        # Filter segments based on their region properties\n",
    "#         if ((0.47 < rectangularity)&(rectangularity < 0.93)) & ((0.71 < solidity) & (solidity < 2.0)) & ((0.26 < form) & (form < 0.81)):\n",
    "        if ((0.6> rectangularity)):\n",
    "            labels.append(region.label)\n",
    "            \n",
    "# Create a mask using labels\n",
    "mask = np.isin(seg, labels)\n",
    "\n",
    "# Mask the array \n",
    "cult_area_fractal = np.ma.masked_array(tmad_median_seg, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vectorize(rect_dict.get)(tmad_seg).astype(float)\n",
    "# fracdimarray = seg.copy().astype(float)\n",
    "# for label in fracdim:\n",
    "#     fracdimarray[fracdimarray == label - 1] = fracdim[label]\n",
    "# print(fracdimarray)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(x)#, vmin= 1.030, vmax=1.2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(cult_area_fractal)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimum threshold \n",
    "# thresh = threshold_otsu(tmad_np) \n",
    "# Filter by the threshold\n",
    "tmad_thresh = tmad_median_seg < thresh\n",
    "# Convert boolean values to binary 1's and 0's\n",
    "tmad_thresh = tmad_thresh*1\n",
    "tmad_thresh = tmad_thresh.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final output\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(tmad_thresh)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fractional cover data\n",
    "\n",
    "fc_data = xr.open_dataset('netcdfs/perthfc.nc')\n",
    "# fc = dc.load(product = 'fc_percentile_albers_annual', **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to show areas where total vegetation is greater than the baresoil fraction of a pixel for each scene\n",
    "tv_mask = fc_data['BS'] < (fc_data['PV'])# + fc_data['NPV'])\n",
    "tv = tv_mask.where(fc_data['PV'] > 0)\n",
    "\n",
    "# Calculate the proportion of time where total vegetatoin is greater than the bare soil fraction of a pixel for the input year\n",
    "tv_summary = tv.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(tv_summary)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(tv_summary)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# x = tv_summary.data\n",
    "# y = tmad_pca\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     sns.jointplot(x=x, y=y, kind=\"hex\", color=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the numpy array\n",
    "\n",
    "# %%time\n",
    "# Note: convert2lab=False allows the use of multiband images\n",
    "seg = quickshift(tv_summary, kernel_size=7, convert2lab=False, max_dist=500, ratio=0.5)\n",
    "print(\"Quickshift number of segments: %d\" % len(np.unique(seg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(mark_boundaries(tv_summary, seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median max ndvi value for each segment\n",
    "import scipy\n",
    "tv_summary_seg = scipy.ndimage.median(input=tv_summary, labels=seg, index=seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(tv_summary_seg)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# Give segments unique labels\n",
    "# labeled = label(cult_area, connectivity = 1)\n",
    "\n",
    "# Create list of labels that do not meet the desired shape requirements\n",
    "frac_dict = {}\n",
    "rect_dict = {}\n",
    "solidity_dict = {}\n",
    "form_dict = {}\n",
    "\n",
    "labels = []\n",
    "for region in regionprops(seg):\n",
    "    if region.area > 1:\n",
    "        fractal_dimension = 2*np.log(region.perimeter/4)/np.log(region.area)\n",
    "        rectangularity = region.area/(region.major_axis_length*region.minor_axis_length)\n",
    "        solidity = region.convex_area / region.area\n",
    "        form = (4*np.pi*region.area)/np.square(region.perimeter)\n",
    "        \n",
    "        # Create dictionary of each property\n",
    "        frac_dict[region.label] = fractal_dimension\n",
    "        rect_dict[region.label] = rectangularity\n",
    "        solidity_dict[region.label] = solidity\n",
    "        form_dict[region.label] = form\n",
    "        \n",
    "        # Filter segments based on their region properties\n",
    "        if ((0.47 < rectangularity)&(rectangularity < 0.93)) & ((0.71 < solidity) & (solidity < 2.0)) & ((0.26 < form) & (form < 0.81)):\n",
    "            labels.append(region.label)\n",
    "            \n",
    "# Create a mask using labels\n",
    "mask = np.isin(seg, labels)\n",
    "\n",
    "# Mask the array \n",
    "cult_area_fractal = np.ma.masked_array(tv_summary_seg, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vectorize(frac_dict.get)(seg).astype(float)\n",
    "# fracdimarray = seg.copy().astype(float)\n",
    "# for label in fracdim:\n",
    "#     fracdimarray[fracdimarray == label - 1] = fracdim[label]\n",
    "# print(fracdimarray)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(x)#, vmin= 1.030, vmax=1.2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(cult_area_fractal)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the segmented summary based on the proportion of time spent dominated by vegetatoin\n",
    "tv_summary_filt = (tv_summary_seg > .3) & (tv_summary_seg < .9)\n",
    "tv_summary_filt = tv_summary_filt*1\n",
    "tv_summary_filt = tv_summary_filt.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,10))\n",
    "plt.imshow(tv_summary_filt)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty numpy array with the same shape as the input\n",
    "img_fill = np.ones((tv_summary.shape))\n",
    "# Assign the segment size values to each value belonging to that \n",
    "seg_size = scipy.ndimage.sum(input=img_fill, labels=seg, index=seg)\n",
    "print(np.unique(seg_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by segment size\n",
    "tv_summary_filt_seg = np.where((seg_size > 500) & (seg_size < 19000), tv_summary_filt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20,10))\n",
    "ax[0].imshow(tv_summary_filt)\n",
    "ax[1].imshow(tv_summary_filt_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_area = np.logical_and(tmad_thresh, tv_summary_filt_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional morphology steps\n",
    "cult_area_filt = ndimage.median_filter(cult_area, 4)\n",
    "# cult_area_filt = np.where(cult_area_filt == True, 1, 0).astype(float)\n",
    "ero_cult = binary_erosion(cult_area, square(2))\n",
    "dil_cult = binary_dilation(ero_cult, square(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot processing stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(cult_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(15,20), sharex=True, sharey=True)\n",
    "ax[0][0].imshow(tmad_pca_seg)\n",
    "ax[0][0].set_title('TMAD')\n",
    "ax[0][1].imshow(tv_summary_seg)\n",
    "ax[0][1].set_title('Fractional cover summary seg')\n",
    "ax[1][0].imshow(cult_area)\n",
    "ax[1][0].set_title('MAD + veg')\n",
    "ax[1][1].imshow(cult_area_filt)\n",
    "ax[1][1].set_title('Median Filter')\n",
    "# fig.savefig('cultareaprocess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert back to xarray / Write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_d = tmad\n",
    "# meta_d = tmad.squeeze().drop('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc_data.BS.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.where(cult_area == True, 1, 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = xr.Dataset({'cultfrac':(meta_d.dims,tmad_thresh_masked)}, coords=meta_d.coords, attrs=meta_d.attrs)\n",
    "# out.attrs = meta_d.attrs\n",
    "# out.attrs['crs']=geometry.CRS(meta_d.crs.attrs['crs_wkt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.write_geotiff('blahtbiggerseg.tif', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_netcdf('caf_pca_snowy2.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
